# üìù Publications 
<!-- Âä†ÁÇπË°®ÊÉÖÂåÖ,Áõ¥Êé•Â§çÂà∂ÂõæÁâáÂç≥ÂèØ  https://github.com/guodongxiaren/README/blob/master/emoji.md?tdsourcetag=s_pcqq_aiomsg -->

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/gefu.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**CVPR 2024**] [Geometry-aware Reconstruction and Fusion-refined Rendering for Generalizable Neural Radiance Fields](https://gefucvpr24.github.io/) \\
**Tianqi Liu**, Xinyi Ye, Min Shi, Zihao Huang, Zhiyu Pan, Zhan Peng, Zhiguo Cao. \\
[[Project page]](https://gefucvpr24.github.io/)
[[Paper]](https://arxiv.org/abs/2404.17528)
[[Code]](https://github.com/TQTQliu/GeFu)
[[Video]](https://youtu.be/Z4RgnsKF3Gs)

We present GeFu, a generalizable NeRF method that synthesizes novel views from multi-view images in a single forward pass.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/RStab.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**CVPR 2024**] [3D Multi-frame Fusion for Video Stabilization](https://arxiv.org/pdf/2404.12887) \\
Zhan Peng, Xinyi Ye, Weiyue Zhao, **Tianqi Liu**, Huiqiang Sun, Baopu Li, Zhiguo Cao. \\
[[Paper]](https://arxiv.org/pdf/2404.12887)
[[Code]](https://github.com/pzzz-cv/RStab)

RStab is a novel framework for video stabilization that integrates 3D multi-frame fusion through volume rendering.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/ETMVSNet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**ICCV 2023**] [When Epipolar Constraint Meets Non-local Operators in Multi-View Stereo](https://arxiv.org/abs/2309.17218) \\
**Tianqi Liu**, Xinyi Ye, Weiyue Zhao, Zhiyu Pan, Min Shi, Zhiguo Cao. \\
[[Paper]](https://arxiv.org/abs/2309.17218)
[[Code]](https://github.com/TQTQliu/ET-MVSNet)

ETMVSNet uses epipolar geometric priors to constrain feature aggregation fileds, thereby efficiently inferring multi-view depths and reconstructing scenes.

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/dmvsnet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**ICCV 2023**] [Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-shaped Depth Cells](https://arxiv.org/abs/2307.09160) \\
Xinyi Ye, Weiyue Zhao, **Tianqi Liu**, Zihao Huang, Zhiguo Cao, Xin Li. \\
[[Paper]](https://arxiv.org/abs/2307.09160)
[[Code]](https://github.com/DIVE128/DMVSNet)

DMVSNet proposes a new perspective to consider the depth geometry of multi-view stereo and introduces a dual-depth approach to approximate the depth geometry with saddle-shaped cells.
</div>
</div>